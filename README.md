# Whisper LoRA Fine-tuning: Online/Offline Setup

μ΄ ν”„λ΅μ νΈλ” Whisper λ¨λΈμ„ LoRA (Low-Rank Adaptation) λ°©λ²•μΌλ΅ νμΈνλ‹ν•λ” κ²ƒμ„ μ¨λΌμΈκ³Ό μ¤ν”„λΌμΈ ν™κ²½μΌλ΅ λ¶„λ¦¬ν• κµ¬ν„μ…λ‹λ‹¤.

## π“ ν”„λ΅μ νΈ κµ¬μ΅°

```
whisper_offline_training/
β”β”€β”€ config.py              # μ„¤μ • νμΌ
β”β”€β”€ utils.py               # μ ν‹Έλ¦¬ν‹° ν•¨μλ“¤
β”β”€β”€ download_data.py       # μ¨λΌμΈ: λ°μ΄ν„°μ…‹ λ‹¤μ΄λ΅λ“ λ° μ „μ²λ¦¬
β”β”€β”€ download_model.py      # μ¨λΌμΈ: λ² μ΄μ¤ λ¨λΈ λ‹¤μ΄λ΅λ“
β”β”€β”€ run_online_setup.py    # μ¨λΌμΈ: μ „μ²΄ μ„¤μ • μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
β”β”€β”€ train_offline.py       # μ¤ν”„λΌμΈ: λ¨λΈ ν•™μµ
β”β”€β”€ evaluate_model.py      # μ¤ν”„λΌμΈ: λ¨λΈ ν‰κ°€
β”β”€β”€ inference.py           # μ¤ν”„λΌμΈ: μ¶”λ΅  λ° λ°λ¨
β”β”€β”€ requirements.txt       # μμ΅΄μ„± ν¨ν‚¤μ§€ λ©λ΅
β””β”€β”€ README.md             # μ‚¬μ© κ°€μ΄λ“
```

## π€ μ„¤μΉ λ° μ„¤μ •

### 1. μμ΅΄μ„± μ„¤μΉ

```bash
pip install -r requirements.txt
```

### 2. CUDA μ„¤μ • (μ„ νƒμ‚¬ν•­)

`config.py`μ—μ„ μ‚¬μ©ν•  GPU λ””λ°”μ΄μ¤λ¥Ό μ„¤μ •ν•  μ μμµλ‹λ‹¤:

```python
cuda_visible_devices: str = "0"  # μ‚¬μ©ν•  GPU ID
```

## π“– μ‚¬μ© λ°©λ²•

### Phase 1: μ¨λΌμΈ μ„¤μ • (μΈν„°λ„· μ—°κ²° ν•„μ”)

μ¨λΌμΈ ν™κ²½μ—μ„ λ‹¤μ μ¤ν¬λ¦½νΈλ¥Ό μ‹¤ν–‰ν•μ—¬ λ¨λ“  λ°μ΄ν„°μ™€ λ¨λΈμ„ λ‹¤μ΄λ΅λ“ν•κ³  μ „μ²λ¦¬ν•©λ‹λ‹¤:

```bash
python run_online_setup.py
```

λλ” κ°λ³„μ μΌλ΅ μ‹¤ν–‰:

```bash
# λ°μ΄ν„°μ…‹ λ‹¤μ΄λ΅λ“ λ° μ „μ²λ¦¬
python download_data.py

# λ² μ΄μ¤ λ¨λΈ λ‹¤μ΄λ΅λ“
python download_model.py
```

μ΄ λ‹¨κ³„μ—μ„ λ‹¤μ μ‘μ—…μ΄ μν–‰λ©λ‹λ‹¤:
- Common Voice ν•κµ­μ–΄ λ°μ΄ν„°μ…‹ λ‹¤μ΄λ΅λ“
- μ¤λ””μ¤ λ°μ΄ν„° λ¦¬μƒν”λ§ (48kHz β†’ 16kHz)
- νΉμ„± μ¶”μ¶ λ° ν† ν¬λ‚μ΄μ μ΄μ…
- Whisper λ² μ΄μ¤ λ¨λΈ μΊμ‹±
- λ¨λ“  λ°μ΄ν„°λ¥Ό λ΅μ»¬ λ””μ¤ν¬μ— μ €μ¥

### Phase 2: μ¤ν”„λΌμΈ ν•™μµ (μΈν„°λ„· μ—°κ²° λ¶ν•„μ”)

μ¤ν”„λΌμΈ ν™κ²½μ—μ„ μ‚¬μ „ μ²λ¦¬λ λ°μ΄ν„°λ¥Ό μ‚¬μ©ν•μ—¬ ν•™μµμ„ μ§„ν–‰ν•©λ‹λ‹¤:

```bash
# λ¨λΈ ν•™μµ
python train_offline.py

# λ¨λΈ ν‰κ°€
python evaluate_model.py

# μ¶”λ΅  λ° λ°λ¨
python inference.py
```

## β™οΈ μ„¤μ • μµμ…

`config.py`μ—μ„ λ‹¤μ μ„¤μ •μ„ μμ •ν•  μ μμµλ‹λ‹¤:

### λ¨λΈ μ„¤μ •
- `model_name_or_path`: λ² μ΄μ¤ Whisper λ¨λΈ ("openai/whisper-small")
- `language`: λ€μƒ μ–Έμ–΄ ("Korean")
- `language_abbr`: μ–Έμ–΄ μ½”λ“ ("ko")
- `task`: μ‘μ—… μ ν• ("transcribe")

### LoRA μ„¤μ •
- `lora_r`: LoRA rank (32)
- `lora_alpha`: LoRA alpha (64)
- `lora_dropout`: LoRA dropout (0.05)
- `target_modules`: μ μ©ν•  λ¨λ“ (["q_proj", "v_proj"])

### ν•™μµ μ„¤μ •
- `per_device_train_batch_size`: ν•™μµ λ°°μΉ ν¬κΈ° (8)
- `learning_rate`: ν•™μµλ¥  (1e-3)
- `num_train_epochs`: μ—ν­ μ (3)
- `warmup_steps`: μ›λ°μ—… μ¤ν… (50)

## π“ νΉμ§•

### LoRA (Low-Rank Adaptation)
- μ „μ²΄ λ¨λΈμ μ•½ 1.4%λ§ ν•™μµ (Parameter-Efficient Fine-Tuning)
- λ©”λ¨λ¦¬ ν¨μ¨μ μΈ ν•™μµ
- λΉ λ¥Έ ν•™μµ μ†λ„

### 8-bit μ–‘μν™”
- `bitsandbytes`λ¥Ό μ‚¬μ©ν• INT8 ν•™μµ
- GPU λ©”λ¨λ¦¬ μ‚¬μ©λ‰ λ€ν­ κ°μ†
- Colab T4 GPU (16GB VRAM)μ—μ„λ„ μ‹¤ν–‰ κ°€λ¥

### μ¤ν”„λΌμΈ μ§€μ›
- λ¨λ“  λ°μ΄ν„°μ™€ λ¨λΈμ„ λ΅μ»¬μ— μΊμ‹±
- μΈν„°λ„· μ—°κ²° μ—†μ΄ ν•™μµ κ°€λ¥
- μ¬ν„ κ°€λ¥ν• μ‹¤ν— ν™κ²½

## π” νμΌ μ„¤λ…

### `config.py`
λ¨λ“  μ„¤μ •μ„ κ΄€λ¦¬ν•λ” μ¤‘μ•™ μ„¤μ • νμΌμ…λ‹λ‹¤.

### `utils.py`
λ°μ΄ν„° μ „μ²λ¦¬, λ©”νΈλ¦­ κ³„μ‚° λ“± κ³µν†µ μ ν‹Έλ¦¬ν‹° ν•¨μλ“¤μ„ ν¬ν•¨ν•©λ‹λ‹¤.

### `download_data.py` (μ¨λΌμΈ ν•„μ”)
Common Voice λ°μ΄ν„°μ…‹μ„ λ‹¤μ΄λ΅λ“ν•κ³  Whisper μ…λ ¥ ν•μ‹μΌλ΅ μ „μ²λ¦¬ν•©λ‹λ‹¤.

### `download_model.py` (μ¨λΌμΈ ν•„μ”)
Whisper λ² μ΄μ¤ λ¨λΈμ„ λ‹¤μ΄λ΅λ“ν•κ³  λ΅μ»¬μ— μΊμ‹±ν•©λ‹λ‹¤.

### `train_offline.py` (μ¤ν”„λΌμΈ κ°€λ¥)
LoRAλ¥Ό μ‚¬μ©ν•μ—¬ Whisper λ¨λΈμ„ νμΈνλ‹ν•©λ‹λ‹¤.

### `evaluate_model.py` (μ¤ν”„λΌμΈ κ°€λ¥)
ν•™μµλ λ¨λΈμ„ ν‰κ°€ν•κ³  WER(Word Error Rate)μ„ κ³„μ‚°ν•©λ‹λ‹¤.

### `inference.py` (μ¤ν”„λΌμΈ κ°€λ¥)
ν•™μµλ λ¨λΈλ΅ μ¶”λ΅ μ„ μ‹¤ν–‰ν•κ±°λ‚ Gradio λ°λ¨λ¥Ό μ‹¤ν–‰ν•©λ‹λ‹¤.

## π― μ›ν¬ν”λ΅μ°

1. **μ¨λΌμΈ ν™κ²½μ—μ„**:
   ```bash
   python run_online_setup.py
   ```

2. **μ¤ν”„λΌμΈ ν™κ²½μΌλ΅ νμΌ μ΄λ™**:
   - μ „μ²΄ ν”„λ΅μ νΈ ν΄λ”λ¥Ό μ¤ν”„λΌμΈ ν™κ²½μΌλ΅ λ³µμ‚¬

3. **μ¤ν”„λΌμΈ ν™κ²½μ—μ„**:
   ```bash
   python train_offline.py    # ν•™μµ
   python evaluate_model.py   # ν‰κ°€
   python inference.py        # μ¶”λ΅ 
   ```

## π“ μ£Όμμ‚¬ν•­

1. **λ©”λ¨λ¦¬ μ”κµ¬μ‚¬ν•­**: μµμ† 16GB GPU λ©”λ¨λ¦¬ κ¶μ¥
2. **λ””μ¤ν¬ κ³µκ°„**: λ°μ΄ν„°μ…‹κ³Ό λ¨λΈ μΊμ‹±μ„ μ„ν•΄ μ¶©λ¶„ν• κ³µκ°„ ν™•λ³΄
3. **Python λ²„μ „**: Python 3.8 μ΄μƒ κ¶μ¥
4. **CUDA**: CUDA μ§€μ› GPU ν•„μ”

## π”§ νΈλ¬λΈ”μν…

### ImportError λ°μƒ μ‹
```bash
pip install --upgrade transformers datasets peft bitsandbytes
```

### CUDA λ©”λ¨λ¦¬ λ¶€μ΅± μ‹
`config.py`μ—μ„ λ°°μΉ ν¬κΈ°λ¥Ό μ¤„μ΄μ„Έμ”:
```python
per_device_train_batch_size: int = 4  # κΈ°λ³Έκ°’: 8
per_device_eval_batch_size: int = 4   # κΈ°λ³Έκ°’: 8
```

### ν•™μµ μ†λ„ κ°μ„ 
`config.py`μ—μ„ gradient accumulationμ„ μ΅°μ •ν•μ„Έμ”:
```python
gradient_accumulation_steps: int = 2  # κΈ°λ³Έκ°’: 1
```

## π“„ λΌμ΄μ„ μ¤

μ΄ ν”„λ΅μ νΈλ” μ›λ³Έ Hugging Face λ…ΈνΈλ¶μ„ κΈ°λ°μΌλ΅ ν•λ©°, κµμ΅ λ° μ—°κµ¬ λ©μ μΌλ΅ μ‚¬μ©λ©λ‹λ‹¤. 